{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WagnerMiron/introducao_a_ciencia_de_dados/blob/main/04-bias-variance-tradeoff-lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Bias and Variance Tradeoff"
      ],
      "metadata": {
        "id": "_t7lBzQbcyBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Introduction\n",
        "In this notebook, we will explore the concepts of bias and variance, which are crucial in understanding the performance of machine learning models. We will demonstrate these concepts using synthetic data, simple linear regression models, and cross-validation."
      ],
      "metadata": {
        "id": "TQppiCV1c71u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Importing Libraries"
      ],
      "metadata": {
        "id": "OO7UKgRNdF6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # Importa a biblioteca NumPy para operações matemáticas e arrays\n",
        "import pandas as pd  # Importa a biblioteca pandas para manipulação de dados\n",
        "import matplotlib.pyplot as plt # Importa matplotlib para criação de gráficos\n",
        "from sklearn.linear_model import LinearRegression # Importa o modelo de Regressão Linear\n",
        "from sklearn.preprocessing import PolynomialFeatures # Importa para criar características polinomiais\n",
        "from sklearn.metrics import mean_squared_error # Importa a função para calcular o erro quadrático médio (MSE)\n",
        "from sklearn.model_selection import train_test_split # Importa a função para dividir os dados em treino e teste\n",
        "from mlxtend.evaluate import bias_variance_decomp # Importa a função para decompor viés e variância do modelo"
      ],
      "metadata": {
        "id": "XZNpjR5bc-te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Creating Synthetic Data"
      ],
      "metadata": {
        "id": "QPBGMbffdUH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate synthetic data\n",
        "def generate_synthetic_data(n_samples=100, noise=1.0, random_seed=42): # Define uma função chamada generate_synthetic_data com três parâmetros: n_samples=100: Número de amostras a serem geradas igual a 100; noise=1.0: A quantidade de ruído a ser adicionado aos dados igual a 1; random_seed=42: Gerador de números aleatórios valor padrão é 42.\n",
        "    np.random.seed(random_seed) # Define a semente aleatória\n",
        "    X = np.linspace(0, 100, n_samples).reshape(-1, 1) # Gera uma matriz de amostras igualmente espaçadas entre 0 e 100\n",
        "    true_function = -0.0001 * X**3 + 0.01 * X**2 + 0.1 * X + 1 # Define a função verdadeira para gerar os valores de y\n",
        "    y = true_function + np.random.normal(scale=noise, size=X.shape) # Adiciona ruído normal aos valores gerados pela função verdadeira\n",
        "    return X, y, true_function # Retorna os dados de entrada (X), os valores de saída (y) e a função verdadeira\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y, true_function = generate_synthetic_data(n_samples=100, noise=2.0)  # Chama a função para gerar dados com 100 amostras e ruído de 2.0"
      ],
      "metadata": {
        "id": "JUGb7mHqdYfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Divide os dados em conjuntos de treinamento e teste, com 20% dos dados reservados para teste"
      ],
      "metadata": {
        "id": "sbGBTOhOddBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Simple Linear Regression Model"
      ],
      "metadata": {
        "id": "ri_ha2VfdfjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training a simple linear regression model\n",
        "lin_reg = LinearRegression() # Cria uma instância do modelo de Regressão Linear\n",
        "lin_reg.fit(X_train, y_train) # Treina o modelo usando os dados de treinamento\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = lin_reg.predict(X_train) # Faz previsões para os dados de treinamento\n",
        "y_test_pred = lin_reg.predict(X_test) # Faz previsões para os dados de teste"
      ],
      "metadata": {
        "id": "rBAb5v7AdkWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the results\n",
        "plt.scatter(X_train, y_train, color='blue', label='Training data') # Plota os dados de treinamento como pontos azuis\n",
        "plt.scatter(X_test, y_test, color='green', label='Testing data') # Plota os dados de teste como pontos verdes\n",
        "plt.plot(X_train, y_train_pred, color='red', label='Linear regression') # Plota a linha de regressão linear em vermelho\n",
        "plt.xlabel('Feature') # Define o rótulo do eixo x como 'Feature'\n",
        "plt.ylabel('Target') # Define o rótulo do eixo y como 'Target'\n",
        "plt.title('Linear Regression Model') # Define o título do gráfico como 'Linear Regression Model'\n",
        "plt.legend() # Adiciona a legenda ao gráfico\n",
        "plt.show() # Exibe o gráfico"
      ],
      "metadata": {
        "id": "sGXxKx6qdn93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating training and testing errors\n",
        "train_error = mean_squared_error(y_train, y_train_pred)  # Calcula o erro quadrático médio (MSE) para os dados de treinamento\n",
        "test_error = mean_squared_error(y_test, y_test_pred) # Calcula o erro quadrático médio (MSE) para os dados de teste\n",
        "print(f'Training Error: {train_error}') # Exibe o erro de treinamento\n",
        "print(f'Testing Error: {test_error}') # Exibe o erro de teste"
      ],
      "metadata": {
        "id": "lddigFYNdqIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, why training MSE is greater than test MSE?"
      ],
      "metadata": {
        "id": "Q6E7LgjaF9Vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Polynomial Regression Models"
      ],
      "metadata": {
        "id": "HfvM3QzPdtrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and plot polynomial models of different degrees\n",
        "degrees = [1, 2, 3, 15]  # Lista dos graus dos polinômios a serem ajustados\n",
        "colors = ['orange', 'red', 'black', 'cyan'] # Lista de cores para cada grau de polinômio\n",
        "predictions = [] # Lista para armazenar previsões dos modelos polinomiais\n",
        "\n",
        "for degree, color in zip(degrees, colors): # Itera sobre os graus dos polinômios e as cores correspondentes\n",
        "    poly_features = PolynomialFeatures(degree=degree, include_bias=False) # Cria características polinomiais para o grau especificado\n",
        "    X_poly = poly_features.fit_transform(X) # Transforma os dados de entrada em características polinomiais\n",
        "    model = LinearRegression() # Cria uma instância do modelo de Regressão Linear\n",
        "    model.fit(X_poly, y) # Ajusta o modelo aos dados polinomiais\n",
        "    y_poly_pred = model.predict(X_poly)  # Faz previsões usando o modelo ajustado\n",
        "    predictions.append(y_poly_pred) # Adiciona as previsões à lista de previsões\n",
        "    plt.plot(X, y_poly_pred, label=f'Degree {degree}', color=color) # Plota as previsões do modelo polinomial no gráfico\n",
        "\n",
        "# Plot the synthetic data and the true function\n",
        "plt.scatter(X, y, facecolors='none', edgecolors='black', label='Data') # Plota os dados sintéticos como pontos com borda preta\n",
        "plt.plot(X, true_function, label='True Function', color='blue') # Plota a função verdadeira em azul\n",
        "plt.xlabel('Feature (X)') # Define o rótulo do eixo x como 'Feature (X)'\n",
        "plt.ylabel('Target (Y)') # Define o rótulo do eixo y como 'Target (Y)'\n",
        "plt.title('Data and Polynomial Fits')  # Define o título do gráfico como 'Data and Polynomial Fits'\n",
        "plt.legend() # Adiciona a legenda ao gráfico\n",
        "plt.show() # Exibe o gráfico"
      ],
      "metadata": {
        "id": "FhBC9VROG4SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Bias-Variance Tradeoff"
      ],
      "metadata": {
        "id": "rfaVy7XOd2sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bias-variance tradeoff is a fundamental concept in machine learning. It describes the tradeoff between two sources of error that affect the performance of a model:\n",
        "\n",
        "- **Bias**: Error due to overly simplistic assumptions in the learning algorithm. High bias can cause the model to miss the relevant relations between features and target outputs (underfitting).\n",
        "- **Variance**: Error due to too much complexity in the learning algorithm. High variance can cause the model to model the random noise in the training data (overfitting).\n",
        "\n",
        "To visualize the bias-variance tradeoff, we can plot the training and testing errors for models of varying complexity."
      ],
      "metadata": {
        "id": "InhiiNRUd_0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and plot training and test MSE\n",
        "train_errors = [] # Inicializa uma lista para armazenar os erros quadráticos médios (MSE) para os dados de treinamento\n",
        "test_errors = [] # Inicializa uma lista para armazenar os erros quadráticos médios (MSE) para os dados de teste\n",
        "flexibility = [] # Inicializa uma lista para armazenar os graus dos polinômios (flexibilidade) usados nos modelos\n",
        "\n",
        "for degree in range(1, 21):  # Itera sobre os graus dos polinômios de 1 a 20\n",
        "    poly_features = PolynomialFeatures(degree=degree, include_bias=False) # Cria características polinomiais para o grau atual\n",
        "    X_train_poly = poly_features.fit_transform(X_train) # Transforma os dados de treinamento em características polinomiais\n",
        "    X_test_poly = poly_features.fit_transform(X_test) # Transforma os dados de teste em características polinomiais\n",
        "\n",
        "    model = LinearRegression() # Cria uma instância do modelo de Regressão Linear\n",
        "    model.fit(X_train_poly, y_train) # Ajusta o modelo aos dados de treinamento polinomiais\n",
        "\n",
        "    y_train_pred = model.predict(X_train_poly) # Faz previsões para os dados de treinamento polinomiais\n",
        "    y_test_pred = model.predict(X_test_poly) # Faz previsões para os dados de teste polinomiais\n",
        "\n",
        "    train_errors.append(mean_squared_error(y_train, y_train_pred)) # Calcula e armazena o MSE para os dados de treinamento\n",
        "    test_errors.append(mean_squared_error(y_test, y_test_pred)) # Calcula e armazena o MSE para os dados de teste\n",
        "    flexibility.append(degree) # Adiciona o grau do polinômio à lista de flexibilidade\n",
        "\n",
        "plt.plot(flexibility, train_errors, label='Training MSE', color='gray', marker='o') # Plota o MSE de treinamento em função do grau do polinômio\n",
        "plt.plot(flexibility, test_errors, label='Test MSE', color='red', marker='o') # Plota o MSE de teste em função do grau do polinômio\n",
        "plt.xlabel('Flexibility (Polynomial Degree)') # Define o rótulo do eixo x como 'Flexibility (Polynomial Degree)'\n",
        "plt.ylabel('Error') # Define o rótulo do eixo y como 'Error'\n",
        "plt.title('Bias-Variance Tradeoff') # Define o título do gráfico como 'Bias-Variance Tradeoff'\n",
        "plt.xticks(flexibility)  # Define os valores do eixo x com os graus dos polinômios\n",
        "plt.legend() # Adiciona a legenda ao gráfico\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5) # Adiciona uma grade ao gráfico com linhas tracejadas\n",
        "plt.show() # Exibe o gráfico com todos os elementos plotados"
      ],
      "metadata": {
        "id": "DK99WHgxFXHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Conclusion"
      ],
      "metadata": {
        "id": "gdMFSEy0eE7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we explored the concepts of bias and variance and demonstrated how they affect the performance of machine learning models. We trained linear and polynomial regression models on synthetic data and visualized the bias-variance tradeoff.\n",
        "\n",
        "Understanding and managing the bias-variance tradeoff is crucial for building models that generalize well to new, unseen data. By balancing bias and variance, we can achieve better performance and more reliable predictions."
      ],
      "metadata": {
        "id": "YOaQ_76pelgR"
      }
    }
  ]
}